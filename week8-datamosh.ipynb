{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51843f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25da9bc",
   "metadata": {},
   "source": [
    "# Week 9 Data Moshing \n",
    "\n",
    "This weeks examples are built from \n",
    "\n",
    "https://github.com/tiberiuiancu/datamoshing\n",
    "\n",
    "and \n",
    "\n",
    "https://ffglitch.org/\n",
    "\n",
    "## Preprocess\n",
    "\n",
    "It can help to normalise the resolution and other factors on our images so the process works best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "12ebbe87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(v, g=\"max\", scale = [640, 480], fps = 25, trim = \"00:00:30\"):\n",
    "    output = v.split(\".\")[0]+\"_processed.mpg\" \n",
    "    result = subprocess.run(['bin/ffgac',\n",
    "        '-i', f'{v}',\n",
    "        '-vf', f'scale={scale[0]}:{scale[1]}',\n",
    "        '-r', f'{fps}',\n",
    "        '-t',f'{trim}',\n",
    "        '-mpv_flags', '+nopimb+forcemv',\n",
    "        '-qscale:v', \"0\", \n",
    "        '-sc_threshold','max',\n",
    "        '-g',f'{g}',\n",
    "        '-vcodec', 'mpeg2video',\n",
    "        '-y',f'{output}'],\n",
    "        stdout=subprocess.DEVNULL,\n",
    "        stderr=subprocess.DEVNULL,\n",
    "        check=True )\n",
    "    return result\n",
    "\n",
    "# # Copy audio stream back from original\n",
    "def put_back_audio(video, audio):\n",
    "    output = video.split(\".\")[0]+\"_audio.mpg\" \n",
    "    result = subprocess.run(['ffmpeg',\n",
    "                    '-i',f'{video}',\n",
    "                    '-i',f'{audio}',\n",
    "                    '-vcodec','mpeg2video',\n",
    "                    '-c:a','copy',\n",
    "                    '-map','0:v:0',\n",
    "                    '-map','1:a:0',\n",
    "                    \"-y\",f'{output}'],\n",
    "                    stdout=subprocess.DEVNULL,\n",
    "                    stderr=subprocess.DEVNULL,\n",
    "                    check=True )\n",
    "    result = subprocess.run(['rm',f'{video}'],\n",
    "                    stdout=subprocess.DEVNULL,\n",
    "                    stderr=subprocess.DEVNULL,\n",
    "                    check=True )\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69d7eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = preprocess(\"images/taylor_original.mp4\")\n",
    "result = preprocess(\"images/taylor_rec.mp4\")\n",
    "result = preprocess(\"images/advert_bbc4_library_1024x576.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b015ab",
   "metadata": {},
   "source": [
    "## Manual Algorithms \n",
    "\n",
    "There are two ways we can edit the `motion vectors` of our video\n",
    "\n",
    "1. By manually editting them. We do this by writing a script which iterates through them and makes any changes to the vertical or horizontal motion of each macroblock in each frame\n",
    "\n",
    "2. By taking the motion vectors from another video\n",
    "\n",
    "### Shift  \n",
    "\n",
    "We provide a separate `.py` file that describes the changes we want to make, in this case `shift.py`. It has **one function** called `mosh_frames(frames)`. Here, we get the motion vectors, have a change to edit them in place, and then return the updated versions.\n",
    "\n",
    "Here we get the average vertical movement for each frame (across all macroblocks) and then uniform up or down motion based on that\n",
    "\n",
    "```python\n",
    "def mosh_frames(frames):\n",
    "    #step through time\n",
    "    for frame in frames:\n",
    "        if not frame:\n",
    "            continue\n",
    "        #Get average vertical movement for this frame\n",
    "        mean_vertical = np.mean(np.array(frame)[:,:,1])\n",
    "        #step through macroblocks\n",
    "        for row in frame:\n",
    "            for mv in row:\n",
    "                #if average is positive make 2, else make -2\n",
    "                mv[1] = 2 if mean_vertical > 0 else -2\n",
    "    return frames\n",
    "```\n",
    "\n",
    "### Resetting I-Frames\n",
    "\n",
    "The more I-Frames we have, the more our glitches get a change to reset \n",
    "\n",
    "Normally we would go \n",
    "\n",
    "```\n",
    "I-frame → P-frame₁ → P-frame₂ → P-frame₃\n",
    "   ↓         ↓         ↓         ↓\n",
    "Perfect → Accurate → Accurate → Accurate\n",
    "```\n",
    "\n",
    "But when we mess with the motion vectors our errors compound\n",
    "```\n",
    "I-frame → P-frame₁ → P-frame₂ → P-frame₃\n",
    "   ↓         ↓         ↓         ↓\n",
    "Perfect → WRONG → MORE WRONG → VERY WRONG\n",
    "```\n",
    "\n",
    "It gets progressively worse until we hit a new I-frame.\n",
    "\n",
    "1. P-frame₁ uses corrupted motion vectors → pixels end up in wrong places\n",
    "\n",
    "2. P-frame₂ predicts from the already-corrupted P-frame₁ → compounds the error\n",
    "\n",
    "3. P-frame₃ predicts from the doubly-corrupted P-frame₂ → even worse\n",
    "\n",
    "4. Continues until next I-frame which \"resets\" the corruption\n",
    "\n",
    "In some contexts, we might want to completely remove any resets to continue our glitching, or we might want to reset occassionaly to get back to the original content. \n",
    "\n",
    "We provide the `g` argument to our scripts to control how often we insert I-frames, with `\"max\"` just being basically none. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba52942",
   "metadata": {},
   "outputs": [],
   "source": [
    "#File to datamosh\n",
    "original = \"images/taylor_original_processed.mpg\"\n",
    "output = original.split(\".\")[0]+\"_shift.mpg\" \n",
    "#Path to the script that describes the changes\n",
    "script = 'shift.py'\n",
    "#gop_period (the gap between \"resetting\" I-frames)\n",
    "g = \"100\"\n",
    "result = subprocess.run(['python3',\n",
    "                'vector_motion.py', f'{original}',\n",
    "                '-s', f'{script}',\n",
    "                '-g',f'{g}',\n",
    "                '-o',output ],\n",
    "                stdout=subprocess.DEVNULL,\n",
    "                stderr=subprocess.DEVNULL,\n",
    "                check=True)\n",
    "result = put_back_audio(output,original)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8da68c",
   "metadata": {},
   "source": [
    "## Removing vertical motion\n",
    "\n",
    "Here it looks like the mouths aren't moving, because this is vertical motion!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "0081eff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#File to datamosh\n",
    "original = \"images/taylor_original_processed.mpg\"\n",
    "output = original.split(\".\")[0]+\"_horizontal.mpg\" \n",
    "#Path to the script that describes the changes\n",
    "script = 'horizontal_motion_example.py'\n",
    "#gop_period (the gap between \"resetting\" I-frames)\n",
    "g = \"100\"\n",
    "result = subprocess.run(['python3',\n",
    "                'vector_motion.py', f'{original}',\n",
    "                '-s', f'{script}',\n",
    "                '-g',f'{g}',\n",
    "                '-o',output ],\n",
    "                stdout=subprocess.DEVNULL,\n",
    "                stderr=subprocess.DEVNULL,\n",
    "                check=True)\n",
    "result = put_back_audio(output,original)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6d9f82",
   "metadata": {},
   "source": [
    "## Averaging Motion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "ddc9d6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = preprocess(\"images/advert_bbc4_library_1024x576.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "27361eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#File to datamosh\n",
    "original = \"images/advert_bbc4_library_1024x576_processed.mpg\"\n",
    "output = original.split(\".\")[0]+\"_mean.mpg\" \n",
    "#Path to the script that describes the changes\n",
    "script = 'average_motion_example.py'\n",
    "#gop_period (the gap between \"resetting\" I-frames)\n",
    "g = \"max\"\n",
    "result = subprocess.run(['python3',\n",
    "                'vector_motion.py', f'{original}',\n",
    "                '-s', f'{script}',\n",
    "                '-g',f'{g}',\n",
    "                '-o',output ],\n",
    "                stdout=subprocess.DEVNULL,\n",
    "                stderr=subprocess.DEVNULL,\n",
    "                check=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00bf2af3",
   "metadata": {},
   "source": [
    "## Transferring motion across videos \n",
    "\n",
    "In this use case I have made `fft visualisation` of the taylor swift audio in `Dorothy`, then used this as the motion to glitch the original video. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30af055a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Strip audio\n",
    "original = \"images/taylor_original_processed.mpg\"\n",
    "output = original.split(\".\")[0]+\".wav\" \n",
    "result = subprocess.run(['ffmpeg',\n",
    "                '-i',f'{original}',\n",
    "                f'{output}'],\n",
    "                stdout=subprocess.DEVNULL,\n",
    "                stderr=subprocess.DEVNULL,\n",
    "                check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2ac5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transfer motion\n",
    "#Recording of output from \"week9-taylor.py\"\n",
    "motion = \"images/taylor_rec_processed.mpg\"\n",
    "original = \"images/taylor_original_processed.mpg\"\n",
    "output = original.split(\".\")[0]+\"_transfer.mpg\" \n",
    "#gop_period (the gap between \"resetting\" I-frames)\n",
    "g = \"100\"\n",
    "result = subprocess.run(['python3',\n",
    "                'style_transfer.py',\n",
    "                #extract motion\n",
    "                '-e', f'{motion}',\n",
    "                #transfer to\n",
    "                '-t', f'{original}',\n",
    "                '-g',f'{g}',\n",
    "                f'{output}'],\n",
    "                stdout=subprocess.DEVNULL,\n",
    "                stderr=subprocess.DEVNULL,\n",
    "                check=True)\n",
    "result = put_back_audio(output,original)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de65ac17",
   "metadata": {},
   "source": [
    "Or we can use the Taylor Swift motion to move this BBC advert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "84cc71a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transfer motion\n",
    "original = \"images/advert_bbc4_library_1024x576_processed.mpg\"\n",
    "motion = \"images/taylor_original_processed.mpg\"\n",
    "output = original.split(\".\")[0]+\"_transfer.mpg\" \n",
    "#gop_period (the gap between \"resetting\" I-frames)\n",
    "g = \"30\"\n",
    "result = subprocess.run(['python3',\n",
    "                'style_transfer.py',\n",
    "                #extract motion\n",
    "                '-e', f'{motion}',\n",
    "                #transfer to\n",
    "                '-t', f'{original}',\n",
    "                '-g',f'{g}',\n",
    "                f'{output}'],\n",
    "                stdout=subprocess.DEVNULL,\n",
    "                stderr=subprocess.DEVNULL,\n",
    "                check=True)\n",
    "result = put_back_audio(output,motion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289db82a",
   "metadata": {},
   "source": [
    "# Exploration \n",
    "\n",
    "Experiment with different videos and different `gop periods` \n",
    "\n",
    "1. Make your own scripts  \n",
    "\n",
    "    * Random values \n",
    "\n",
    "    * Constant values \n",
    "\n",
    "    * Changes in scale (amplify movement e.g `mv[0] = 2 * mv[0]`)\n",
    "\n",
    "    * Different changes based on frame number \n",
    "\n",
    "    * Different changes based on location in frame (coordinate)\n",
    "\n",
    "2. Merge a `Dorothy` sketch with a video \n",
    "\n",
    "3. Merge two videos \n",
    "\n",
    "4. Make your own videos to merge\n",
    "\n",
    "## How do I get videos?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7432db13",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dorothy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
